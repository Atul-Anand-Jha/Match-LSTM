data:
  dataset:
    train_path: cmrc_data/CMRC/cmrc2018_train.json
    dev_path: cmrc_data/CMRC/cmrc2018_dev.json
  dataset_h5: cmrc_data/cmrc_embedding.h5
  ignore_max_len: 600 # in train data, context token len > ignore_max_len will be dropped

  embedding_path: /Users/han/cmrc/embedding/sgns.merge.word.bz2
#  embedding_path: /Users/han/cmrc/embedding/sgns.target.word-character.char1-2.dynwin5.thr10.neg5.dim300.iter5.bz2

  model_path: cmrc_data/model-weight.pt
  checkpoint_path: cmrc_data/checkpoint

global:
  random_seed: 123
  model: base # 'match-lstm', 'match-lstm+', 'r-net' or 'base'. Note that 'base' model is customized by base_model.yaml

train:
  batch_size: 32
  valid_batch_size: 32
  epoch: 30
  enable_cuda: True

  optimizer: 'adamax'  # adam, sgd, adamax, adadelta(default is adamax)
  learning_rate: 0.002  # only for sgd
  clip_grad_norm: 5

test:
  batch_size: 32
  enable_cuda: True
  is_english: False # judge what character two words split with, ' ' for english, '' for chinese